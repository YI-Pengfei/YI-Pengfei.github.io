<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://YI-Pengfei.github.io</id>
    <title>飞天小南鲸</title>
    <updated>2020-04-23T02:23:39.805Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://YI-Pengfei.github.io"/>
    <link rel="self" href="https://YI-Pengfei.github.io/atom.xml"/>
    <subtitle>记得戴口罩</subtitle>
    <logo>https://YI-Pengfei.github.io/images/avatar.png</logo>
    <icon>https://YI-Pengfei.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, 飞天小南鲸</rights>
    <entry>
        <title type="html"><![CDATA[UAV路径规划综述总结]]></title>
        <id>https://YI-Pengfei.github.io/post/uav-lu-jing-gui-hua-zong-shu-zong-jie/</id>
        <link href="https://YI-Pengfei.github.io/post/uav-lu-jing-gui-hua-zong-shu-zong-jie/">
        </link>
        <updated>2020-04-22T02:23:00.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>
<p><a href="https://ieeexplore.ieee.org/document/7053093">A Literature Review of UAV 3D Path Planning</a><br>
<img src="https://YI-Pengfei.github.io/post-images/1587522271745.jpg" alt="" loading="lazy"><br>
<img src="https://YI-Pengfei.github.io/post-images/1587522283490.png" alt="" loading="lazy"></p>
</li>
<li>
<p><a href="https://ieeexplore-ieee-org-443.e2.buaa.edu.cn/document/7953494">Offline and Online Search: UAV Multiobjective<br>
Path Planning Under Dynamic Urban Environment</a><br>
<img src="https://YI-Pengfei.github.io/post-images/1587608593156.png" alt="" loading="lazy"></p>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[堆优化的A*算法-Python实现]]></title>
        <id>https://YI-Pengfei.github.io/post/dui-you-hua-de-asuan-fa-python-shi-xian/</id>
        <link href="https://YI-Pengfei.github.io/post/dui-you-hua-de-asuan-fa-python-shi-xian/">
        </link>
        <updated>2020-03-27T02:45:13.000Z</updated>
        <content type="html"><![CDATA[<h3 id="堆优化的a算法-python实现">堆优化的A*算法-Python实现</h3>
<ul>
<li><a href="https://blog.csdn.net/FengKuangXiaoZuo/article/details/105135005">笔者CSDN博客地址</a></li>
<li><a href="https://blog.csdn.net/weixin_44489823/article/details/89382502">原理参考博客地址</a></li>
<li><a href="https://blog.csdn.net/gzlaiyonghao/article/details/1329956">代码借鉴地址</a></li>
</ul>
<p>A*算法解决二维网格地图中的寻路问题</p>
<ul>
<li>输入：图片（白色区域代表可行，深色区域代表不行可行）</li>
<li>输出：路径（在图中绘制）</li>
</ul>
<pre><code class="language-python">&quot;&quot;&quot; 方格地图中的A*算法 (openList进行了堆优化)
A* 算法：  F = G+H
F: 总移动代价
G: 起点到当前点的移动代价  直:1, 斜:1.4
H: 当前点到终点的预估代价  曼哈顿距离
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
1.把起点加入 openList中
2.While True:
    a.遍历openList，查找F值最小的节点，作为current
    b.current是终点:
        ========结束========
    c.从openList中弹出，放入closeList中
    d.对八个方位的格点:
        if 越界 or 是障碍物 or 在closeList中:
            continue
        if 不在openList中：
            设置父节点,F,G,H
            加入openList中
        else:
            if 这条路径更好:
                设置父节点,F,G
                更新openList中的对应节点
3.生成路径path
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
堆优化:
    openList：作为最小堆，按F值排序存储坐标 （不更新只增加）
    openDict：坐标:点详细信息 （既更新又增加）
    get_minfNode() 从openList中弹出坐标，去openDict中取点 （但由于不更新只增加，坐标可能冗余）
    in_openList() 判断坐标是否在openDict中即可 

&quot;&quot;&quot;
import math
from PIL import Image,ImageDraw 
import numpy as np
import heapq # 堆

STAT_OBSTACLE='#'
STAT_NORMAL='.'

def manhattan(x1,y1, x2,y2):
    &quot;&quot;&quot;两个Point的曼哈顿距离&quot;&quot;&quot;
    h = abs(x1-x2)+abs(y1-y2)
    return h

class Node():
    &quot;&quot;&quot;
    开放列表和关闭列表的元素类型，parent用来在成功的时候回溯路径
    &quot;&quot;&quot;
    def __init__(self, x, y,parent=None, g=0, h=0):
        self.parent = parent
        self.x = x
        self.y = y
        self.g = g
        self.h = h
        self.update()
    
    def update(self):
        self.f = self.g+self.h


class A_Star:
    &quot;&quot;&quot; x是行索引，y是列索引
    &quot;&quot;&quot;
    def __init__(self, test_map, start=None, end=None):
        &quot;&quot;&quot;地图，起点，终点&quot;&quot;&quot;
        self.map = test_map
        self.cols = len(test_map[0])
        self.rows = len(test_map)
        self.startXY = tuple(start) if start else (0,0)
        self.endXY = tuple(end) if end else (self.rows-1, self.cols-1)
        self.closeList = set()
        self.path = []
        self.openList = []  # 堆，只添加，和弹出最小值点，
        self.openDict = dict() # openList中的 坐标:详细信息 --&gt;不冗余的
        
    
    def find_path(self):
        &quot;&quot;&quot;A*算法寻路主程序&quot;&quot;&quot;
        p = Node(self.startXY[0], self.startXY[1], 
                 h=manhattan(self.startXY[0],self.startXY[1], self.endXY[0],self.endXY[1])) # 构建开始节点
        heapq.heappush(self.openList, (p.f,(p.x,p.y)))
        
        self.openDict[(p.x,p.y)] = p  # 加进dict目录
        while True:
            current = self.get_minfNode()
            if (current.x,current.y)==self.endXY:
                print('found path successfully..')
                self.make_path(current)
                return 
            
            self.closeList.add((current.x,current.y))  ## 加入closeList
            del self.openDict[(current.x,current.y)]
            self.extend_surrounds(current) # 会更新close list

    def make_path(self,p):
        &quot;&quot;&quot;从结束点回溯到开始点，开始点的parent==None&quot;&quot;&quot;
        while p:
            self.path.append((p.x, p.y))
            p = p.parent
    
    def extend_surrounds(self, node):
        &quot;&quot;&quot; 将当前点周围可走的点加到openList中，
            其中 不在openList中的点 设置parent、F,G,H 加进去，
                 在openList中的点  更新parent、F,G,H
        &quot;&quot;&quot;
        motion_direction = [[1, 0], [0,  1], [-1, 0], [0,  -1], 
                            [1, 1], [1, -1], [-1, 1], [-1, -1]]  
        for dx, dy in motion_direction:
            x,y = node.x+dx, node.y+dy
            new_node = Node(x,y)
            # 位置无效，或者是障碍物, 或者已经在closeList中 
            if not self.is_valid_xy(x,y) or not self.not_obstacle(x,y) or self.in_closeList(new_node): 
                continue
            if abs(dx)+abs(dy)==2:  ## 斜向
                h_x,h_y = node.x+dx,node.y # 水平向
                v_x,v_y = node.x,node.y+dy # 垂直向
                if not self.is_valid_xy(h_x,h_y) or not self.not_obstacle(h_x,h_y) or self.in_closeList(Node(h_x,h_y)): 
                    continue
                if not self.is_valid_xy(v_x,v_y) or not self.not_obstacle(v_x,v_y) or self.in_closeList(Node(v_x,v_y)): 
                    continue
            #============ ** 关键 **             ========================
            #============ 不在openList中，加进去； ========================
            #============ 在openList中，更新      ========================
            #============对于openList和openDict来说，操作都一样 ===========
            new_g = node.g + self.cal_deltaG(node.x,node.y, x,y)
            sign=False # 是否执行操作的标志 
            if not self.in_openList(new_node): # 不在openList中
                # 加进来，设置 父节点, F, G, H
                new_node.h = self.cal_H(new_node)
                sign=True
            elif self.openDict[(new_node.x,new_node.y)].g &gt; new_g: # 已在openList中，但现在的路径更好
                sign=True
            if sign:
                new_node.parent = node
                new_node.g = new_g
                new_node.f = self.cal_F(new_node)
                self.openDict[(new_node.x,new_node.y)]=new_node # 更新dict目录
                heapq.heappush(self.openList, (new_node.f,(new_node.x,new_node.y)))
        
    def get_minfNode(self):
        &quot;&quot;&quot;从openList中取F=G+H值最小的 (堆-O(1))&quot;&quot;&quot;
        while True:
            f, best_xy=heapq.heappop(self.openList)
            if best_xy in self.openDict:
                return self.openDict[best_xy]

    def in_closeList(self, node):
        &quot;&quot;&quot;判断是否在closeList中 (集合-O(1)) &quot;&quot;&quot;
        return True if (node.x,node.y) in self.closeList else False
     
    def in_openList(self, node):
        &quot;&quot;&quot;判断是否在openList中 (字典-O(1))&quot;&quot;&quot;
        if not (node.x,node.y) in self.openDict:
            return False
        else:
            return True

    def is_valid_xy(self, x,y):
        if x &lt; 0 or x &gt;= self.rows or y &lt; 0 or y &gt;= self.cols:
            return False
        return True
        
    def not_obstacle(self,x,y):
        return self.map[x][y] != STAT_OBSTACLE
    
    def cal_deltaG(self,x1,y1,x2,y2):
        &quot;&quot;&quot; 计算两点之间行走的代价
            （为简化计算）上下左右直走，代价为1.0，斜走，代价为1.4  G值
        &quot;&quot;&quot;
        if x1 == x2 or y1 == y2:
            return 1.0
        return 1.4
    
    def cal_H(self, node):
        &quot;&quot;&quot; 曼哈顿距离 估计距离目标点的距离&quot;&quot;&quot;
        return abs(node.x-self.endXY[0])+abs(node.y-self.endXY[1]) # 剩余路径的估计长度
    
    def cal_F(self, node):
        &quot;&quot;&quot; 计算F值 F = G+H 
            A*算法的精髓：已经消耗的代价G，和预估将要消耗的代价H
        &quot;&quot;&quot;
        return node.g + node.h

def plot(test_map,path):
    &quot;&quot;&quot;绘制地图和路径
        test_map:二维数组
        path:路径坐标数组
    &quot;&quot;&quot;
    out = []
    for x in range(len(test_map)):
        temp = []
        for y in range(len(test_map[0])):
            if test_map[x][y]==STAT_OBSTACLE:
                temp.append(0)
            elif test_map[x][y]==STAT_NORMAL:
                temp.append(255)
            elif test_map[x][y]=='*':
                temp.append(127)
            else:
                temp.append(255)
        out.append(temp)
    for x,y in path:
        out[x][y] = 127
    out = np.array(out)
    img = Image.fromarray(out)
    img.show()

def path_length(path):
    &quot;&quot;&quot;计算路径长度&quot;&quot;&quot;
    l = 0
    for i in range(len(path)-1):
        x1,y1 = path[i]
        x2,y2 = path[i+1]
        if x1 == x2 or y1 == y2:
            l+=1.0
        else:
            l+=1.4
    return l
    

def img_to_map(img_file):
    &quot;&quot;&quot;地图图片变二维数组&quot;&quot;&quot;
    test_map = []
    img = Image.open(img_file)
    img = img.resize((100,100))  ### resize图片尺寸
    img_gray = img.convert('L')  # 地图灰度化
    img_arr = np.array(img_gray)
    img_binary = np.where(img_arr&lt;127,0,255)
    for x in range(img_binary.shape[0]):
        temp_row = []
        for y in range(img_binary.shape[1]):
            status = STAT_OBSTACLE if img_binary[x,y]==0 else STAT_NORMAL 
            temp_row.append(status)
        test_map.append(temp_row)
    
    return test_map

# ===== test case ===============
test_map=img_to_map('map_1.bmp')
a = A_Star(test_map)
a.find_path()
plot(test_map,a.path)
print('path length:',path_length(a.path))
</code></pre>
<h3 id="测试用例及结果">测试用例及结果</h3>
<p><img src="https://YI-Pengfei.github.io/post-images/1585357842632.png" alt="" loading="lazy"><br>
<img src="https://YI-Pengfei.github.io/post-images/1585357848707.png" alt="" loading="lazy"><br>
<img src="https://YI-Pengfei.github.io/post-images/1585357856210.png" alt="" loading="lazy"></p>
<h3 id="存在的问题">存在的问题</h3>
<p>不确定是否是最优路径<br>
原文描述：<br>
“ If we overestimate this distance, however, it is not guaranteed to give us the shortest path. In such cases, we have what is called an &quot;inadmissible heuristic.&quot;.</p>
<p>Technically, in this example, the Manhattan method is inadmissible because it slightly overestimates the remaining distance.”<br>
即如果我们高估了H，则不能保证最短路径。而曼哈顿距离略微高估了。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[智能优化算法]]></title>
        <id>https://YI-Pengfei.github.io/post/zhi-neng-you-hua-suan-fa/</id>
        <link href="https://YI-Pengfei.github.io/post/zhi-neng-you-hua-suan-fa/">
        </link>
        <updated>2020-03-01T01:11:22.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/Frank_LJiang/article/details/90949775">https://blog.csdn.net/Frank_LJiang/article/details/90949775</a><br>
<a href="https://blog.csdn.net/Sinde1992/article/details/50321225">https://blog.csdn.net/Sinde1992/article/details/50321225</a></p>
<h3 id="进化类算法">进化类算法：</h3>
<ul>
<li>遗传算法 起源于20世纪60年代</li>
<li>差分进化算法 1995年</li>
<li>免疫算法 1973年</li>
</ul>
<h3 id="群智能算法">群智能算法</h3>
<ul>
<li>蚁群算法  1992年</li>
<li>粒子群优化算法  1995年</li>
</ul>
<h3 id="模拟退火算法">模拟退火算法</h3>
<h3 id="禁忌搜索算法">禁忌搜索算法</h3>
<h3 id="神经网络算法">神经网络算法</h3>
<p>为了找出地球上最高的山，一群兔子开始想办法</p>
<ol>
<li>兔子朝着比现在高的地方跳去。他们找到了不远处的最高山峰。但是这座山不一定是珠穆朗玛峰。这就是<strong>局部搜索</strong>，它不能保证局部最优值就是全局最优值。</li>
<li>兔子喝醉了。他随机地跳了很长时间。这期间，它可能走向高处，也可能踏入平地。但是，他渐渐清醒了并朝最高方向跳去。这就是<strong>模拟退火</strong>。</li>
<li>兔子们吃了失忆药片，并被发射到太空，然后随机落到了地球上的某些地方。他们不知道自己的使命是什么。但是，如果你过几年就杀死一部分海拔低的兔子，多产的兔子们自己就会找到珠穆朗玛峰。这就是<strong>遗传算法</strong>。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Python画图 三维]]></title>
        <id>https://YI-Pengfei.github.io/post/python-hua-tu-san-wei/</id>
        <link href="https://YI-Pengfei.github.io/post/python-hua-tu-san-wei/">
        </link>
        <updated>2020-02-27T23:16:14.000Z</updated>
        <content type="html"><![CDATA[<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo>)</mo><mo>=</mo><mn>5</mn><mi>s</mi><mi>i</mi><mi>n</mi><mo>(</mo><mi>x</mi><mi>y</mi><mo>)</mo><mo>+</mo><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><msup><mi>y</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">f(x,y)=5sin(xy)+x^2+y^2
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">5</span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.9474379999999999em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.0585479999999998em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p>
<pre><code class="language-python">from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm
import matplotlib.pyplot as plt
import numpy as np
import mpl_toolkits.mplot3d
import math

def func(X):
    x,y=X[0],X[1]
    &quot;&quot;&quot;x,y为两个数值变量&quot;&quot;&quot;
    z = 5*np.sin(x*y)+x**2+y**2
    return z

def plot():
    figure=plt.figure()
    #ax = Axes3D(figure)
    ax=figure.gca(projection=&quot;3d&quot;)
    x1=np.arange(-4,4,0.02)
    y1=np.arange(-4,4,0.02)
    x,y =np.meshgrid(x1,y1)
    z=func([x,y])
    #ax.plot_surface(x,y,z,rstride=10,cstride=4,cmap=cm.YlGnBu_r)
    ax.plot_surface(x,y,z,cmap=&quot;rainbow&quot;)
    plt.show()

plot()
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://YI-Pengfei.github.io/post-images/1582852756703.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[应用tflearn实现神经网络-一个简单的例子]]></title>
        <id>https://YI-Pengfei.github.io/post/ying-yong-tflearn-shi-xian-shen-jing-wang-luo-yi-ge-jian-dan-de-li-zi/</id>
        <link href="https://YI-Pengfei.github.io/post/ying-yong-tflearn-shi-xian-shen-jing-wang-luo-yi-ge-jian-dan-de-li-zi/">
        </link>
        <updated>2020-02-21T03:16:47.000Z</updated>
        <content type="html"><![CDATA[<p>tflearn官方文档 <a href="http://tflearn.org/">http://tflearn.org/</a><br>
&quot;&quot;&quot;<br>
练习tensorflow和tflearn<br>
&quot;&quot;&quot;</p>
<pre><code class="language-python">import tensorflow as tf
import tflearn
import numpy as np
import random
from matplotlib import pyplot as plt

tf.reset_default_graph()

def generate_data(n=5, num=1000):
    &quot;&quot;&quot;产生测试用的数据&quot;&quot;&quot;
    d = [0,1]

    allX = []
    allY = []
    for count in range(num):
        lst = []
        label = [0,1]
        for i in range(n):
            rnd = random.choice(d)
            if len(lst)&gt;=1 and rnd==1 and rnd==lst[-1]:
                label = [1,0]   ## 有连续两个1
            lst.append(rnd)
        allX.append(lst)
        allY.append(label)
    ## 随机将数据分为两组，训练组 和 测试组
    allX = np.array(allX)
    allY = np.array(allY)
    trainIndex = sorted(random.sample(list(range(num)), int(num/5)))
    testIndex = sorted(list(set(range(num))- set(trainIndex)))
    trainX, trainY = allX[trainIndex,:], allY[trainIndex ,:]
    testX, testY = allX[testIndex,:], allY[testIndex ,:]

    return trainX, trainY, testX, testY


def train_model(trainX, trainY, acti):
    &quot;&quot;&quot;构建神经网络，训练神经网络&quot;&quot;&quot;
    n_in, n_out = len(trainX[0]), len(trainY[0])
    net = tflearn.input_data(shape=[None, n_in])
    net = tflearn.fully_connected(net, 8, activation=acti)
    net = tflearn.fully_connected(net, 8, activation=acti)
    net = tflearn.fully_connected(net, n_out, activation=acti)
    net = tflearn.regression(net, optimizer='adam', 
                             loss='categorical_crossentropy',
                             learning_rate=0.01)
    
    model = tflearn.DNN(net, tensorboard_verbose=3)
    model.fit(trainX, trainY, n_epoch=100, show_metric=True, batch_size=50)
    return model


def test_model(model, testX, testY):
    &quot;&quot;&quot;测试神经网络&quot;&quot;&quot;
    pred = model.predict(testX)
    n_right=0
    for i,lst in enumerate(pred):
        if lst[0]&gt;lst[1]:
            res = [1,0]
        else:
            res = [0,1]
        if res==testY[i].tolist():
            n_right+=1
        
    accuracy = n_right/len(pred)
    return accuracy


trainX, trainY, testX, testY = generate_data(n=5, num=1000)
model = train_model(trainX, trainY, acti='softmax') # 训练模型
accuracy = test_model(model, testX, testY)
print('Predict accuracy is:%f'%accuracy)
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[关联规则学习 Association rule learning]]></title>
        <id>https://YI-Pengfei.github.io/post/guan-lian-gui-ze-xue-xi-association-rule-learning/</id>
        <link href="https://YI-Pengfei.github.io/post/guan-lian-gui-ze-xue-xi-association-rule-learning/">
        </link>
        <updated>2020-02-21T03:06:05.000Z</updated>
        <content type="html"><![CDATA[<p><a href="http://rasbt.github.io/mlxtend/api_subpackages/mlxtend.frequent_patterns/">http://rasbt.github.io/mlxtend/api_subpackages/mlxtend.frequent_patterns/</a><br>
&quot;&quot;&quot;<br>
关联规则学习 Association rule learning 的目的是从大数据中发现变量之间的相关性<br>
如&quot;啤酒和尿布&quot;的故事<br>
Apriori alogrithm<br>
实现Apriori alogrithm 用 mlxtend.frequent_patterns<br>
&quot;&quot;&quot;</p>
<pre><code class="language-python">import pandas as pd
from mlxtend.frequent_patterns import apriori
from mlxtend.frequent_patterns import association_rules
## 创建数据
columns = ['Milk', 'Bread', 'Butter', 'Beer', 'Diaper']
L_transactions=[[1,1,0,0,0],
                [0,0,1,0,0],
                [0,0,0,1,1],
                [1,1,1,0,0],
                [0,1,0,0,0]]
df = pd.DataFrame(L_transactions, columns=columns)

frequent_itemsets=apriori(df,min_support=0.4)  ## 计算频繁项集 p&gt;0.4
print(frequent_itemsets)

rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)  ## 求关联规则
print(rules)
</code></pre>
<p>输出：</p>
<pre><code class="language-python">   support itemsets
0      0.4      (0)
1      0.6      (1)
2      0.4      (2)
3      0.4   (0, 1)
  antecedents consequents     ...      leverage  conviction
0         (0)         (1)     ...          0.16         inf
1         (1)         (0)     ...          0.16    1.800000

[2 rows x 9 columns]
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[无监督学习-Kmeans聚类和 层次聚类]]></title>
        <id>https://YI-Pengfei.github.io/post/wu-jian-du-xue-xi-kmeans-ju-lei-he-ceng-ci-ju-lei/</id>
        <link href="https://YI-Pengfei.github.io/post/wu-jian-du-xue-xi-kmeans-ju-lei-he-ceng-ci-ju-lei/">
        </link>
        <updated>2020-02-21T02:18:15.000Z</updated>
        <content type="html"><![CDATA[<p>&quot;&quot;&quot;<br>
Kmeans聚类和 层次聚类<br>
<a href="https://scikit-learn.org/stable/modules/clustering.html#clustering">https://scikit-learn.org/stable/modules/clustering.html#clustering</a><br>
&quot;&quot;&quot;</p>
<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
import sklearn.cluster
SIZES,SEED,k,num=20,0,5,2
colors=[&quot;ro&quot;,&quot;b*&quot;,&quot;gs&quot;,&quot;y^&quot;,&quot;kx&quot;]
Algorithms=[&quot;Kmeans&quot;,&quot;Hierarchical-Single&quot;,&quot;Hierarchical-Average&quot;,&quot;Hierarchical-Maximum&quot;]
la=len(Algorithms)
Lx=np.concatenate([np.cos(np.arange(0,np.pi,0.01))*(100+j)/100+np.random.rand(int(np.pi/0.01)+1)*0.05 for j in range(num)]+[np.cos(np.arange(0,np.pi,0.01))*(100+j)/200+np.random.rand(int(np.pi/0.01)+1)*0.05 for j in range(num)])
Ly=np.concatenate([np.sin(np.arange(0,np.pi,0.01))*(100+j)/100+np.random.rand(int(np.pi/0.01)+1)*0.05 for j in range(num)]+[np.sin(np.arange(0,np.pi,0.01))*(100+j)/200+np.random.rand(int(np.pi/0.01)+1)*0.05 for j in range(num)])
n=len(Lx)
c=np.sqrt((Lx-Lx.reshape(n,1))**2+(Ly-Ly.reshape(n,1))**2)  # 为什么这个是目标？？？ 代价函数：误差平方和（SSE）
fig=plt.figure(figsize=(8,4*la))
for i in range(la):
    if Algorithms[i]==&quot;Kmeans&quot;:
        y_pred = sklearn.cluster.KMeans(n_clusters=k,random_state=SEED).fit_predict(list(zip(Lx,Ly)))
    elif Algorithms[i]==&quot;Hierarchical-Single&quot;:
        y_pred = sklearn.cluster.AgglomerativeClustering(linkage=&quot;ward&quot;, n_clusters=k).fit_predict(list(zip(Lx,Ly)))
    elif Algorithms[i]==&quot;Hierarchical-Average&quot;:
        y_pred = sklearn.cluster.AgglomerativeClustering(linkage=&quot;average&quot;, n_clusters=k).fit_predict(list(zip(Lx,Ly)))
    elif Algorithms[i]==&quot;Hierarchical-Maximum&quot;:
        y_pred = sklearn.cluster.AgglomerativeClustering(linkage=&quot;complete&quot;, n_clusters=k).fit_predict(list(zip(Lx,Ly)))

    ax = plt.subplot(la,2,i+1)
    for j in range(n):

        cluster = y_pred[j]
        plt.plot(Lx[j],Ly[j],colors[cluster],markersize=5)

    ax.set_title(Algorithms[i],fontsize=SIZES)
#plt.savefig(&quot;C12Clustering.pdf&quot;,bbox_inches='tight')
#plt.close()
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://YI-Pengfei.github.io/post-images/1582256775343.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[leNet5卷积网络]]></title>
        <id>https://YI-Pengfei.github.io/post/lenet5-juan-ji-wang-luo/</id>
        <link href="https://YI-Pengfei.github.io/post/lenet5-juan-ji-wang-luo/">
        </link>
        <updated>2020-02-17T02:13:14.000Z</updated>
        <content type="html"><![CDATA[<p>对mnist数据集训练leNet5卷积网络<br>
<img src="https://YI-Pengfei.github.io/post-images/1581906013166.png" alt="" loading="lazy"></p>
<ul>
<li>mnist_lenet5_forward.py</li>
</ul>
<pre><code class="language-python">import tensorflow as tf
IMAGE_SIZE = 28
NUM_CHANNELS = 1 # 单通道
CONV1_SIZE = 5 # 卷积核尺寸 5*5*1*32
CONV1_KERNEL_NUM = 32 ## 卷积核的个数
CONV2_SIZE = 5
CONV2_KERNEL_NUM = 64
FC_SIZE = 512 # 全连接层 512
OUTPUT_NODE = 10

def get_weight(shape, regularizer):
    &quot;&quot;&quot;权重生成函数
    shape: 生成张量的维度
    regularizer: 正则化权重
    &quot;&quot;&quot;
    w = tf.Variable(tf.truncated_normal(shape, stddev=0.1), dtype=tf.float32) # 创建方法在 3.2节
    if regularizer!=None:  # L2正则化
        tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(regularizer)(w))
    return w

def get_bias(shape):
    # 生成 偏置
    b = tf.Variable(tf.constant(0.5, shape=shape)) # shape=[11]
    return b

def conv2d(x,w):
    &quot;&quot;&quot;卷积计算函数&quot;&quot;&quot;
    return tf.nn.conv2d(x, # 输入描述 [batch,行分辨率,列分辨率,通道数]
                        w, # 卷积核描述 [行分辨率,列分辨率,通道数,卷积核个数]
                        strides=[1,1,1,1], # 核滑动步长[1,行步长,列步长,1]，
                        padding='SAME'  # 填充模式
                        )

def max_pool_2x2(x):
    &quot;&quot;&quot;最大池化函数&quot;&quot;&quot;
    return tf.nn.max_pool(x, # 输入描述 [batch,行分辨率,列分辨率,通道数]
                          ksize=[1,2,2,1], # 池化核描述[1,行分辨率,列分辨率,1]，
                          strides=[1,2,2,1], # 池化核滑动步长[1,行步长,列步长,1]，
                          padding='SAME' # 填充模式
                          )
    

def forward(x, train, regularizer):
    conv1_w = get_weight([CONV1_SIZE, CONV1_SIZE,NUM_CHANNELS, CONV1_KERNEL_NUM], regularizer)
    conv1_b = get_bias([CONV1_KERNEL_NUM])
    conv1 = conv2d(x, conv1_w)  # 卷积
    relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_b)) # 加偏置
    pool1 = max_pool_2x2(relu1)  # 最大池化
    
    conv2_w = get_weight([CONV2_SIZE, CONV2_SIZE, CONV1_KERNEL_NUM, CONV2_KERNEL_NUM], regularizer)
    conv2_b = get_bias([CONV2_KERNEL_NUM])
    conv2 = conv2d(pool1, conv2_w)
    relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_b))
    pool2 = max_pool_2x2(relu2)
    
    pool_shape = pool2.get_shape().as_list()
    nodes = pool_shape[1]*pool_shape[2]*pool_shape[3]  # 特征的长度*宽度*深度
    reshaped = tf.reshape(pool2, [pool_shape[0], nodes])  # pool_shape[0] 是一个BATCH的值
    
    fc1_w = get_weight([nodes, FC_SIZE], regularizer)
    fc1_b = get_bias([FC_SIZE])
    fc1 = tf.nn.relu(tf.matmul(reshaped, fc1_w) + fc1_b)
    if train: # 训练时使用dropout
        fc1 = tf.nn.dropout(fc1, 0.5)
    
    fc2_w = get_weight([FC_SIZE, OUTPUT_NODE], regularizer)
    fc2_b = get_bias([OUTPUT_NODE])
    y = tf.matmul(fc1, fc2_w)+fc2_b
    return y
</code></pre>
<ul>
<li>mnist_lenet5_backward.py</li>
</ul>
<pre><code class="language-python"># -*- coding: utf-8 -*-
&quot;&quot;&quot;
Created on Mon Feb 17 08:56:24 2020

@author: y1064
&quot;&quot;&quot;

import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import mnist_lenet5_forward
import os
import numpy as np

BATCH_SIZE = 100
LEARNING_RATE_BASE = 0.005
LEARNING_RATE_DECAY = 0.99
REGULARIZER = 0.0001
STEPS = 50000
MOVING_AVERAGE_DECAY = 0.99
MODEL_SAVE_PATH = 'model/'
MODEL_NAME = 'mnist_model'

def backward(mnist):
    x = tf.placeholder(tf.float32,  ## 输入是四阶张量
                       [
                        BATCH_SIZE,
                        mnist_lenet5_forward.IMAGE_SIZE,
                        mnist_lenet5_forward.IMAGE_SIZE,
                        mnist_lenet5_forward.NUM_CHANNELS
                               ])
    y_ = tf.placeholder(tf.float32, 
                        [None, mnist_lenet5_forward.OUTPUT_NODE])
    y = mnist_lenet5_forward.forward(x, True, REGULARIZER)
    global_step = tf.Variable(0, trainable=False)
    
    ce = tf.nn.sparse_softmax_cross_entropy_with_logits(
            logits=y, labels=tf.argmax(y_, 1))
    cem = tf.reduce_mean(ce)
    loss = cem + tf.add_n(tf.get_collection('losses'))
    
    learning_rate = tf.train.exponential_decay(
            LEARNING_RATE_BASE,
            global_step,
            mnist.train.num_examples/BATCH_SIZE,
            LEARNING_RATE_DECAY,
            staircase = True)
    
    train_step = tf.train.GradientDescentOptimizer(
            learning_rate).minimize(loss, global_step=global_step)
    
    ema = tf.train.ExponentialMovingAverage(
            MOVING_AVERAGE_DECAY, global_step)
    ema_op = ema.apply(tf.trainable_variables())
    with tf.control_dependencies([train_step, ema_op]):
        train_op = tf.no_op(name='train')
    
    saver = tf.train.Saver()
    
    with tf.Session() as sess:
        init_op = tf.global_variables_initializer()
        sess.run(init_op)
        
        ckpt = tf.train.get_checkpoint_state(MODEL_SAVE_PATH)
        if ckpt and ckpt.model_checkpoint_path:
            saver.restore(sess, ckpt.model_checkpoint_path)
        
        for i in range(STEPS):
            xs, ys = mnist.train.next_batch(BATCH_SIZE)
            ## 这样reshape就能变成四阶张量？？、
            reshaped_xs = np.reshape(xs, (
                        BATCH_SIZE,
                        mnist_lenet5_forward.IMAGE_SIZE,
                        mnist_lenet5_forward.IMAGE_SIZE,
                        mnist_lenet5_forward.NUM_CHANNELS))
            _, loss_value, step = sess.run([train_op, loss, global_step],
                                           feed_dict={x:reshaped_xs, y_:ys})
            if i%100==0:
                print(&quot;After %d training steps, loss on training batch is %g.&quot;%(step, loss_value))
                saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)

def main():
    mnist = input_data.read_data_sets('./data/', one_hot=True)
    backward(mnist)

if __name__=='__main__':
    main()
</code></pre>
<ul>
<li>mnist_lenet5_test.py</li>
</ul>
<pre><code class="language-python"># -*- coding: utf-8 -*-
&quot;&quot;&quot;
Created on Mon Feb 17 09:16:06 2020

@author: y1064
&quot;&quot;&quot;
import time
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import mnist_lenet5_forward
import mnist_lenet5_backward
import os
import numpy as np

TEST_INTERVAL_SECS = 5

def test(mnist):
    with tf.Graph().as_default() as g:
        x = tf.placeholder(tf.float32, [
                mnist.test.num_examples,
                mnist_lenet5_forward.IMAGE_SIZE,
                mnist_lenet5_forward.IMAGE_SIZE,
                mnist_lenet5_forward.NUM_CHANNELS
                ])
        y_ = tf.placeholder(tf.float32, 
                            [None, mnist_lenet5_forward.OUTPUT_NODE])
        y = mnist_lenet5_forward.forward(x, False, None)
        
        ema = tf.train.ExponentialMovingAverage(
                mnist_lenet5_backward.MOVING_AVERAGE_DECAY)
        ema_restore = ema.variables_to_restore()
        saver = tf.train.Saver(ema_restore)
        
        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_,1))
        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
        
        while True:
            with tf.Session() as sess:
                ckpt = tf.train.get_checkpoint_state(mnist_lenet5_backward.MODEL_SAVE_PATH)
                if ckpt and ckpt.model_checkpoint_path:
                    saver.restore(sess, ckpt.model_checkpoint_path)
                    
                    global_step = ckpt.model_checkpoint_path.split('/')[-1].split(' ')[-1]
                    reshaped_x = np.reshape(mnist.test.images, (
                            mnist.test.num_examples,
                            mnist_lenet5_forward.IMAGE_SIZE,
                            mnist_lenet5_forward.IMAGE_SIZE,
                            mnist_lenet5_forward.NUM_CHANNELS
                            ))
                    accuracy_score = sess.run(accuracy, feed_dict = {
                            x:reshaped_x,
                            y_:mnist.test.labels
                            })
                    print('After %s training steps, test accuracy=%g'%(global_step, accuracy_score))
                else:
                    print('No checkpoint file found')
            
            time.sleep(TEST_INTERVAL_SECS)

def main():
    mnist = input_data.read_data_sets('./data/', one_hot=True)
    test(mnist)
    
if __name__=='__main__':
    main()
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[图搜索算法]]></title>
        <id>https://YI-Pengfei.github.io/post/sou-suo-suan-fa/</id>
        <link href="https://YI-Pengfei.github.io/post/sou-suo-suan-fa/">
        </link>
        <updated>2020-02-16T04:20:38.000Z</updated>
        <content type="html"><![CDATA[<h3 id="bfs">BFS</h3>
<p>按层扩展<br>
<img src="https://YI-Pengfei.github.io/post-images/1581826896242.gif" alt="BFS示意图" loading="lazy"><br>
<img src="https://YI-Pengfei.github.io/post-images/1582596932039.png" alt="BFS-按深度层序的" loading="lazy"></p>
<h4 id="bfs基本代码">BFS基本代码：</h4>
<pre><code class="language-python">import networkx as nx

G = nx.Graph()
G.add_edge(1,2)
G.add_edge(2,4)
G.add_edge(2,3)
G.add_edge(3,5)

def bfs(G,node):
    res = []
    visited = {}
    for node in G.nodes(): # 标记所有节点为 &quot;未访问&quot;
        visited[node] = False
    queue = [node]
    visited[node] = True
    while queue:
        cur_node = queue.pop(0) # 队头出列
        res.append(cur_node)
        for child in nx.neighbors(G, cur_node):
            if not visited[child]:
                visited[child]=True
                queue.append(child) # 入队尾
    return res

print(bfs(G,5))
</code></pre>
<h4 id="bfs搜索od之间的路径">BFS搜索OD之间的路径</h4>
<figure data-type="image" tabindex="1"><img src="https://YI-Pengfei.github.io/post-images/1582547464448.png" alt="有向图示例" loading="lazy"></figure>
<pre><code class="language-python">&quot;&quot;&quot;
BFS找源到目的的路径 从S到E的路径:BFS一定能找到路径，但是不一定是最短路径长度，而是最小深度
&quot;&quot;&quot;
import networkx as nx

G = nx.DiGraph()
G.add_edge('S','A',weight=2)
G.add_edge('S','B',weight=1)
G.add_edge('S','C',weight=6)

G.add_edge('A','D',weight=6)
G.add_edge('A','E',weight=20)

G.add_edge('B','E',weight=20)
G.add_edge('CA','E',weight=8)

def BFS(G,O,D):
    &quot;&quot;&quot;
    G:有向图，O:源节点，D:目的节点
    &quot;&quot;&quot;
    record = {} ## 记录每一个节点的父节点
    queue = [O]
    print('root node is:', O)
    found=False  ## 
    while not found:
        if not queue:
            break
        cur_node = queue.pop(0) # 弹出队列第一个元素
        for child in G.neighbors(cur_node):
            print(child)
            record[child]=cur_node
            queue.append(child)
            if child==D:
                found=True
    
    if not D in record:
        print('not found target node')
        return -1
    path = [] # 组装路径
    while D in record:
        path.insert(0,(record[D],D))
        D = record[D]
    
    return path

print(BFS(G, 'S', 'E')) # 
&gt;&gt; [('S', 'A'), ('A', 'E')]
</code></pre>
<h3 id="dfs">DFS</h3>
<p>按深度扩展<br>
<img src="https://YI-Pengfei.github.io/post-images/1582596960531.png" alt="DFS-不撞南墙不回头的" loading="lazy"></p>
<h4 id="dfs基本代码递归">DFS基本代码(递归)：</h4>
<pre><code class="language-python">import networkx as nx

G = nx.Graph()
G.add_edge(1,2)
G.add_edge(2,4)
G.add_edge(2,3)
G.add_edge(3,5)

def dfs(G,node,visited={},res=[]):
    if not visited: # first run, mark all as unvisited
        for node in G.nodes():
            visited[node]=False 
    res.append(node)
    visited[node] = True
    for child in nx.neighbors(G, node):
        if not visited[child]:
            res, visited = dfs(G,child,visited,res)
    return res, visited

res,visited = dfs(G,5,{},[])
</code></pre>
<h4 id="dfs搜索od之间的路径">DFS搜索OD之间的路径</h4>
<pre><code class="language-python">&quot;&quot;&quot;
DFS找源到目的的路径 从S到E的路径. 后进先出&quot;last-in,first out&quot;
非递归方法 取节点(不出栈)，找到一个未被访问过的子节点，标记为访问，并入栈，重复
&quot;&quot;&quot;
import networkx as nx

G = nx.DiGraph()
G.add_edge('S','A',weight=2)
G.add_edge('S','B',weight=1)
G.add_edge('S','C',weight=6)

G.add_edge('A','D',weight=6)
G.add_edge('A','E',weight=20)

G.add_edge('B','E',weight=20)
G.add_edge('CA','E',weight=8)


def DFS(G,O,D):
    queue = [O]
    found=False
    visited = set([O])
    record = {}
    while not found:
        if not queue:  ## 终止条件：队列为空
            break
        
        cur_node = queue[-1] ## 每次都从队尾取节点，往深了访问  &quot;last-in,first out&quot;
        print(cur_node)
        
        if len(list(G.neighbors(cur_node)))==0: # 当前节点是叶子节点(到头了)
            queue.pop(-1) # 栈中弹出该节点 （对该节点的DFS已经结束）
        else:
            sign_children_all_visited = True
            for child in G.neighbors(cur_node):
                if not child in visited: # 发现未被访问过的子节点
                    sign_children_all_visited = False
                    break
            if not sign_children_all_visited:
                visited.add(child) # 添加为已访问
                record[child] = cur_node
                queue.append(child)  # 入栈
            else: # 所有子节点都被访问过
                queue.pop(-1)
        ###### 设置访问到目的节点D就终止 ######
        if child==D:
            found=True
            
    ### 构造路径
    if not D in record:
        print('not found target node')
        return -1
    path = [] # 组装路径
    while D in record:
        path.insert(0,(record[D],D))
        D = record[D]
    
    return path

print(DFS(G, 'S', 'E'))
</code></pre>
<h3 id="dijkstra">Dijkstra</h3>
<p>按最小代价扩展</p>
<h4 id="dijkstra搜索od之间的路径">Dijkstra搜索OD之间的路径:</h4>
<figure data-type="image" tabindex="2"><img src="https://YI-Pengfei.github.io/post-images/1582596978367.png" alt="UCS-一致代价搜索-按花费的" loading="lazy"></figure>
<pre><code class="language-python"># -*- coding: utf-8 -*-
&quot;&quot;&quot;
Dijkstra找源到目的地的最短路径 UCS一致代价搜索 
一致代价搜索总是扩展路径消耗最小的节点N。N点的路径消耗等于前一节点N-1的路径消耗加上N-1到N节点的路径消耗。
通过将 更新的路径 入堆，确保每次取出来的都是最小的路径
&quot;&quot;&quot;
import networkx as nx
import heapq # 堆

G = nx.DiGraph()
G.add_edge('S','A',weight=2)
G.add_edge('S','B',weight=1)
G.add_edge('S','C',weight=6)

G.add_edge('A','D',weight=6)
G.add_edge('A','E',weight=20)

G.add_edge('B','E',weight=20)
G.add_edge('C','E',weight=8)


O='S'
D='D'
def Dijkstra(G, O, D):
    INF=10*10
    dict_sure = {}  ## 记录各个节点的最短路径长度
    dict_path = dict((node,[O]) for node in G) ## 记录路径
    dict_dis = dict((node,INF) for node in G)  ## 记录路径长度（初始化为无穷大）
    dict_dis[O] = 0
    
    heap = []
    heapq.heappush(heap, (0,O))

    while heap:
        dis, cur_node=heapq.heappop(heap)  ##未访问点中距离最小的点和对应的距离
        if cur_node in dict_sure: # 弹出的节点无效(保证是未访问的)
            continue
        dict_sure[cur_node] = dis ## 标记为确定
        path = dict_path[cur_node]
        ### 添加，遇到目的节点D则终止
        if D in dict_sure:
            break
        ###
        for child in G.neighbors(cur_node):
            dis_new = G[cur_node][child]['weight']+dis
            if child not in dict_sure and dict_dis[child]&gt;dis_new: # 路径长度变短了
                heapq.heappush(heap, (dis_new,child)) # 入栈
                dict_dis[child] = dis_new # 更新信息
                dict_path[child] = path+[child]
                
    path = dict_path[D]
    path = [(path[i],path[i+1]) for i in range(len(path)-1)]
    return path, dict_sure[D] # 返回路径，路径长度
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[机器学习笔记]]></title>
        <id>https://YI-Pengfei.github.io/post/ji-qi-xue-xi-bi-ji/</id>
        <link href="https://YI-Pengfei.github.io/post/ji-qi-xue-xi-bi-ji/">
        </link>
        <updated>2020-02-16T01:04:31.000Z</updated>
        <content type="html"><![CDATA[<h3 id="神经元">神经元</h3>
<p>神经网络的基本模型是神经元，神经元的基本模型就是数学中的乘、加运算：<br>
<img src="https://YI-Pengfei.github.io/post-images/1581815704630.png" alt="神经元" loading="lazy"></p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>=</mo><msub><mi>x</mi><mn>1</mn></msub><msub><mi>w</mi><mn>1</mn></msub><mo>+</mo><msub><mi>x</mi><mn>2</mn></msub><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">y=x_1 w_1 + x_2 w_2
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<h3 id="神经网络">神经网络</h3>
<figure data-type="image" tabindex="1"><img src="https://YI-Pengfei.github.io/post-images/1581816066755.png" alt="两层的神经网络（一个隐藏层）" loading="lazy"></figure>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>a</mi><mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow></msup><mo>=</mo><mi>X</mi><msup><mi>W</mi><mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow></msup><mspace linebreak="newline"></mspace><mi>y</mi><mo>=</mo><msup><mi>a</mi><mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow></msup><msup><mi>W</mi><mrow><mo>(</mo><mn>2</mn><mo>)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">a^{(1)}=XW^{(1)} \\
y=a^{(1)}W^{(2)}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.938em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.938em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.938em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>更进一步地，过激活函数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span></span></span></span>以提高表现力的神经元模型：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo>(</mo><munder><mo>∑</mo><mi>i</mi></munder><msub><mi>x</mi><mi>i</mi></msub><msub><mi>w</mi><mi>i</mi></msub><mo>+</mo><mi>b</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">f(\sum_i x_iw_i+b)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.327674em;vertical-align:-1.277669em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0500050000000003em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">b</span><span class="mclose">)</span></span></span></span></span></p>
<p>常用的激活函数有:</p>
<ul>
<li>relu</li>
<li>sigmoid</li>
<li>tanh</li>
<li><a href="https://www.jianshu.com/p/6db999961393">https://www.jianshu.com/p/6db999961393</a><br>
<img src="https://YI-Pengfei.github.io/post-images/1583109874689.png" alt="" loading="lazy"><br>
<img src="https://YI-Pengfei.github.io/post-images/1583540404333.webp" alt="https://www.jianshu.com/p/6db999961393" loading="lazy"></li>
</ul>
<h3 id="损失函数loss">损失函数loss</h3>
<p>计算得到的预测值<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span>与已知答案<span class='katex-error' title='ParseError: KaTeX parse error: Expected group after &#039;_&#039; at position 2: y_̲'>y_</span>的差距：</p>
<ul>
<li>均方误差MSE</li>
<li>自定义损失函数：根据问题的实际情况</li>
<li>交叉熵CE（Cross Entropy）</li>
</ul>
<p>反向传播训练中，以减小loss值为优化目标，有<strong>梯度下降</strong>，<strong>momentum优化器</strong>，<strong>adam优化器</strong>等优化方法。</p>
<h3 id="学习率">学习率</h3>
<p>决定每次参数更新的幅度。在训练过程中，参数的更新向着损失函数梯度下降的方向。参数更新的公式为：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>w</mi><mi>n</mi></msub><mo>−</mo><mi>l</mi><mi>e</mi><mi>a</mi><mi>r</mi><mi>n</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi mathvariant="normal">_</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>e</mi><mi mathvariant="normal">Δ</mi></mrow><annotation encoding="application/x-tex">w_{n+1}=w_n-learning\_rate \Delta
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.638891em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">n</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord">Δ</span></span></span></span></span></p>
<ul>
<li>指数衰减学习率：<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mi>e</mi><mi>a</mi><mi>r</mi><mi>n</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi mathvariant="normal">_</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo>=</mo><mi>L</mi><mi>E</mi><mi>A</mi><mi>R</mi><mi>N</mi><mi>I</mi><mi>N</mi><mi>G</mi><mi mathvariant="normal">_</mi><mi>R</mi><mi>A</mi><mi>T</mi><mi>E</mi><mi mathvariant="normal">_</mi><mi>B</mi><mi>A</mi><mi>S</mi><mi>E</mi><mo>∗</mo><mi>L</mi><mi>E</mi><mi>A</mi><mi>R</mi><mi>N</mi><mi>I</mi><mi>N</mi><mi>G</mi><mi mathvariant="normal">_</mi><mi>R</mi><mi>A</mi><mi>T</mi><mi>E</mi><mi mathvariant="normal">_</mi><mi>D</mi><mi>E</mi><mi>C</mi><mi>A</mi><mi>Y</mi><mo>∗</mo><mfrac><mrow><mi>g</mi><mi>l</mi><mi>o</mi><mi>b</mi><mi>a</mi><mi>l</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>p</mi></mrow><mrow><mi>L</mi><mi>E</mi><mi>A</mi><mi>R</mi><mi>N</mi><mi>I</mi><mi>N</mi><mi>G</mi><mi mathvariant="normal">_</mi><mi>R</mi><mi>A</mi><mi>T</mi><mi>E</mi><mi mathvariant="normal">_</mi><mi>B</mi><mi>A</mi><mi>T</mi><mi>C</mi><mi>H</mi><mi mathvariant="normal">_</mi><mi>S</mi><mi>I</mi><mi>Z</mi><mi>E</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">learning\_rate=LEARNING\_RATE\_BASE * LEARNING\_RATE\_DECAY * \frac{global\_step}{LEARNING\_RATE\_BATCH\_SIZE}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">n</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord mathdefault">L</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">G</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord mathdefault">L</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">G</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.39044em;vertical-align:-0.996em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.39444em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">G</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault" style="margin-right:0.07153em;">Z</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.6999999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault">b</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault">s</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord mathdefault">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.996em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mi>E</mi><mi>A</mi><mi>R</mi><mi>N</mi><mi>I</mi><mi>N</mi><mi>G</mi><mi mathvariant="normal">_</mi><mi>R</mi><mi>A</mi><mi>T</mi><mi>E</mi><mi mathvariant="normal">_</mi><mi>B</mi><mi>A</mi><mi>S</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">LEARNING\_RATE\_BASE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord mathdefault">L</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">G</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span></span></span></span>为学习率初始值（如0.1），<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mi>E</mi><mi>A</mi><mi>R</mi><mi>N</mi><mi>I</mi><mi>N</mi><mi>G</mi><mi mathvariant="normal">_</mi><mi>R</mi><mi>A</mi><mi>T</mi><mi>E</mi><mi mathvariant="normal">_</mi><mi>D</mi><mi>E</mi><mi>C</mi><mi>A</mi><mi>Y</mi></mrow><annotation encoding="application/x-tex">LEARNING\_RATE\_DECAY</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord mathdefault">L</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">G</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span></span></span></span>为学习率衰减率（如0.99），<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>g</mi><mi>l</mi><mi>o</mi><mi>b</mi><mi>a</mi><mi>l</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>p</mi></mrow><annotation encoding="application/x-tex">global\_step</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault">b</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault">s</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord mathdefault">p</span></span></span></span>记录了当前训练轮数，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mi>E</mi><mi>A</mi><mi>R</mi><mi>N</mi><mi>I</mi><mi>N</mi><mi>G</mi><mi mathvariant="normal">_</mi><mi>R</mi><mi>A</mi><mi>T</mi><mi>E</mi><mi mathvariant="normal">_</mi><mi>B</mi><mi>A</mi><mi>T</mi><mi>C</mi><mi>H</mi><mi mathvariant="normal">_</mi><mi>S</mi><mi>I</mi><mi>Z</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">LEARNING\_RATE\_BATCH\_SIZE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord mathdefault">L</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">G</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault" style="margin-right:0.07153em;">Z</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span></span></span></span>表示喂入多少轮<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>B</mi><mi>A</mi><mi>T</mi><mi>C</mi><mi>H</mi><mi mathvariant="normal">_</mi><mi>S</mi><mi>I</mi><mi>Z</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">BATCH\_SIZE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault" style="margin-right:0.07153em;">Z</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span></span></span></span>后，更新一次学习率(一般设为：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">总</mi><mi mathvariant="normal">样</mi><mi mathvariant="normal">本</mi><mi mathvariant="normal">数</mi><mi mathvariant="normal">/</mi><mi>B</mi><mi>A</mi><mi>T</mi><mi>C</mi><mi>H</mi><mi mathvariant="normal">_</mi><mi>S</mi><mi>I</mi><mi>Z</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">总样本数/BATCH\_SIZE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord cjk_fallback">总</span><span class="mord cjk_fallback">样</span><span class="mord cjk_fallback">本</span><span class="mord cjk_fallback">数</span><span class="mord">/</span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault" style="margin-right:0.07153em;">Z</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span></span></span></span>)。</li>
</ul>
<h3 id="滑动平均">滑动平均</h3>
<p>记录一段时间内模型中所有参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">b</span></span></span></span>各自的平均值。利用滑动平均值可以增强模型的泛化能力。计算公式：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">影</mi><mi mathvariant="normal">子</mi><mo>=</mo><mi mathvariant="normal">衰</mi><mi mathvariant="normal">减</mi><mi mathvariant="normal">率</mi><mo>∗</mo><mi mathvariant="normal">影</mi><mi mathvariant="normal">子</mi><mo>+</mo><mo>(</mo><mn>1</mn><mo>−</mo><mi mathvariant="normal">衰</mi><mi mathvariant="normal">减</mi><mi mathvariant="normal">率</mi><mo>)</mo><mo>∗</mo><mi mathvariant="normal">参</mi><mi mathvariant="normal">数</mi></mrow><annotation encoding="application/x-tex">影子=衰减率*影子 + (1-衰减率)*参数
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord cjk_fallback">影</span><span class="mord cjk_fallback">子</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.46528em;vertical-align:0em;"></span><span class="mord cjk_fallback">衰</span><span class="mord cjk_fallback">减</span><span class="mord cjk_fallback">率</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord cjk_fallback">影</span><span class="mord cjk_fallback">子</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord cjk_fallback">衰</span><span class="mord cjk_fallback">减</span><span class="mord cjk_fallback">率</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0em;vertical-align:0em;"></span><span class="mord cjk_fallback">参</span><span class="mord cjk_fallback">数</span></span></span></span></span></p>
<p>其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">衰</mi><mi mathvariant="normal">减</mi><mi mathvariant="normal">率</mi><mo>=</mo><mi>m</mi><mi>i</mi><mi>n</mi><mo>{</mo><mi>M</mi><mi>O</mi><mi>V</mi><mi>I</mi><mi>N</mi><mi>G</mi><mi mathvariant="normal">_</mi><mi>A</mi><mi>V</mi><mi>E</mi><mi>R</mi><mi>A</mi><mi>G</mi><mi>E</mi><mi mathvariant="normal">_</mi><mi>D</mi><mi>E</mi><mi>C</mi><mi>A</mi><mi>Y</mi><mo separator="true">,</mo><mfrac><mrow><mn>1</mn><mo>+</mo><mi mathvariant="normal">轮</mi><mi mathvariant="normal">数</mi></mrow><mrow><mn>10</mn><mo>+</mo><mi mathvariant="normal">轮</mi><mi mathvariant="normal">数</mi></mrow></mfrac><mo>}</mo></mrow><annotation encoding="application/x-tex">衰减率=min\{MOVING\_AVERAGE\_DECAY, \frac{1+轮数}{10+轮数}\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord cjk_fallback">衰</span><span class="mord cjk_fallback">减</span><span class="mord cjk_fallback">率</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2484389999999999em;vertical-align:-0.403331em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mopen">{</span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">G</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault">A</span><span class="mord mathdefault">G</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">0</span><span class="mbin mtight">+</span><span class="mord cjk_fallback mtight">轮</span><span class="mord cjk_fallback mtight">数</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord cjk_fallback mtight">轮</span><span class="mord cjk_fallback mtight">数</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.403331em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">}</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">影</mi><mi mathvariant="normal">子</mi><mi mathvariant="normal">初</mi><mi mathvariant="normal">值</mi><mo>=</mo><mi mathvariant="normal">参</mi><mi mathvariant="normal">数</mi><mi mathvariant="normal">初</mi><mi mathvariant="normal">值</mi></mrow><annotation encoding="application/x-tex">影子初值=参数初值</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mord cjk_fallback">影</span><span class="mord cjk_fallback">子</span><span class="mord cjk_fallback">初</span><span class="mord cjk_fallback">值</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0em;vertical-align:0em;"></span><span class="mord cjk_fallback">参</span><span class="mord cjk_fallback">数</span><span class="mord cjk_fallback">初</span><span class="mord cjk_fallback">值</span></span></span></span>。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>M</mi><mi>O</mi><mi>V</mi><mi>I</mi><mi>N</mi><mi>G</mi><mi mathvariant="normal">_</mi><mi>A</mi><mi>V</mi><mi>E</mi><mi>R</mi><mi>A</mi><mi>G</mi><mi>E</mi><mi mathvariant="normal">_</mi><mi>D</mi><mi>E</mi><mi>C</mi><mi>A</mi><mi>Y</mi></mrow><annotation encoding="application/x-tex">MOVING\_AVERAGE\_DECAY</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mord mathdefault">G</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault">A</span><span class="mord mathdefault">G</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span></span></span></span>表示滑动平均衰减率，一般会赋接近1的值。</p>
<h3 id="正则化">正则化</h3>
<p>在损失函数中给每个参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span></span></span></span>加上权重，引入模型复杂度指标，从而抑制模型噪声，减小过拟合：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>(</mo><mi>y</mi><mi mathvariant="normal">与</mi><mi>y</mi><mi mathvariant="normal">_</mi><mo>)</mo><mo>+</mo><mi>R</mi><mi>E</mi><mi>G</mi><mi>U</mi><mi>L</mi><mi>A</mi><mi>R</mi><mi>I</mi><mi>Z</mi><mi>E</mi><mi>R</mi><mo>∗</mo><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>(</mo><mi>w</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">loss = loss(y与y\_) + REGULARIZER*loss(w)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord cjk_fallback">与</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault">G</span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="mord mathdefault">L</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault" style="margin-right:0.07153em;">Z</span><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mclose">)</span></span></span></span></span></p>
<p>其中，第一项是预测结果与标准答案之前的差距（如交叉熵、均方误差）；第二项是正则化计算结果。</p>
<h2 id="卷积神经网络">卷积神经网络</h2>
<figure data-type="image" tabindex="2"><img src="https://YI-Pengfei.github.io/post-images/1581896531157.png" alt="LeNet-5" loading="lazy"></figure>
]]></content>
    </entry>
</feed>